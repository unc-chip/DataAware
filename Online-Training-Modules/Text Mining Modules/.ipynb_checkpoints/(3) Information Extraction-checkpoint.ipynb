{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Welcome to the third text mining module. In this module, you will learn about Part of Speech Tagging, Named Entity Recognition, and Relation Extraction. Under each session, you will have a short tutorial which shows you how to complete an information extraction task using text mining tool. The goal is to give you hands-on experience on extracting key information using a text mining tool. Section 2, 3, and 4.1, have optional exercises to allow you to get familair with the concepts. The task 4 is a little bit complex but we encourage you to take this challenge, which will help you better understand how we can teach mechine to extract sentence relation. Ok, let's get it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## How to Run the Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Throughout this module you will encounter both text and code cells. Please run each cell in this Notebook by clicking \"Run\" button in the Toolbar or by pushing Shift+Enter keys\n",
    "<br>\n",
    "![run_cell.png](Pictures/run_cell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Part of Speech Tagging (POS Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T17:49:57.274153Z",
     "start_time": "2020-05-29T17:49:57.257277Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"705\" height=\"537\" src=\"https://www.youtube.com/embed/bvP70Bhgbf8?list=PL6IN6GlGifEytPcv5HR_iaNBekwXYZIpR\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import HTML\n",
    "# Display Video\n",
    "HTML('<iframe width=\"705\" height=\"537\" src=\"https://www.youtube.com/embed/bvP70Bhgbf8?list=PL6IN6GlGifEytPcv5HR_iaNBekwXYZIpR\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task 1: POS tags and Noun phrase extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the following, we will take a taste of parsing a text and complete the following tasks\n",
    "* Tag each word with Penn tree bank and universal tags\n",
    "* Extract noun phrases\n",
    "\n",
    "In this module, you will use spaCy to complete the following tasks. You already have had some experience with NLTK in tokenization, lemmatization, stemming. spaCy is a another very useful NLP tool and a strong competiter to NLTK. Unlike NLTK, spaCy takes over the dirty work using an object-oriented approach, which makes text processing easier and faster. For example, it extracts noun phrases without the need to pre-design regex pattern and traverse the parser tree. Instead, you simply \"call\" the noun chunks that spacy has done for you under the hood. \n",
    "\n",
    "Here is a simple code example to extract the noun phrases using spaCy:\n",
    "\n",
    "```python\n",
    "doc = nlp(string_to_process)\n",
    "for np in doc.noun_chunks:\n",
    "    print(np.text)\n",
    "```\n",
    "\n",
    "For additional resources for spaCy 101 tutorial, you can find [here](https://spacy.io/usage/spacy-101). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### How to solve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Import spacy package and load english language model\n",
    "* Get the spacy object of such text\n",
    "* Obtain the pos tagging attributes of each word, word.pos_ and noun chunk results noun.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pos tags of the given text:\n",
      "('Health', 'NN')\n",
      "('informatics', 'NNS')\n",
      "('is', 'VBZ')\n",
      "('information', 'NN')\n",
      "('engineering', 'NN')\n",
      "('applied', 'VBD')\n",
      "('to', 'IN')\n",
      "('the', 'DT')\n",
      "('field', 'NN')\n",
      "('of', 'IN')\n",
      "('health', 'NN')\n",
      "('care', 'NN')\n",
      "(',', ',')\n",
      "('essentially', 'RB')\n",
      "('the', 'DT')\n",
      "('management', 'NN')\n",
      "('and', 'CC')\n",
      "('use', 'NN')\n",
      "('of', 'IN')\n",
      "('patient', 'JJ')\n",
      "('health', 'NN')\n",
      "('care', 'NN')\n",
      "('information', 'NN')\n",
      "********************\n",
      "The universal pos tags of the given text\n",
      "********************\n",
      "('Health', 'NOUN')\n",
      "('informatics', 'NOUN')\n",
      "('is', 'AUX')\n",
      "('information', 'NOUN')\n",
      "('engineering', 'NOUN')\n",
      "('applied', 'VERB')\n",
      "('to', 'ADP')\n",
      "('the', 'DET')\n",
      "('field', 'NOUN')\n",
      "('of', 'ADP')\n",
      "('health', 'NOUN')\n",
      "('care', 'NOUN')\n",
      "(',', 'PUNCT')\n",
      "('essentially', 'ADV')\n",
      "('the', 'DET')\n",
      "('management', 'NOUN')\n",
      "('and', 'CCONJ')\n",
      "('use', 'NOUN')\n",
      "('of', 'ADP')\n",
      "('patient', 'ADJ')\n",
      "('health', 'NOUN')\n",
      "('care', 'NOUN')\n",
      "('information', 'NOUN')\n",
      "********************\n",
      "The extracted noun phrases is: \n",
      "********************\n",
      "Health informatics\n",
      "information engineering\n",
      "the field\n",
      "health care\n",
      "patient health care information\n"
     ]
    }
   ],
   "source": [
    "import spacy                    #import spacy module\n",
    "import en_core_web_sm\n",
    "\n",
    "# load English language model\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "TEXT_SAMPLE = \"\"\"Health informatics is information engineering applied to the field of health care, essentially the management and use of patient health care information \"\"\"\n",
    "\n",
    "doc = nlp(TEXT_SAMPLE)\n",
    "\n",
    "# Obtain tags using pos_tag\n",
    "print(\"The pos tags of the given text:\")\n",
    "for tok in doc:\n",
    "    print((tok.text, tok.tag_))\n",
    "\n",
    "print(\"*\"*20)          \n",
    "print(\"The universal pos tags of the given text\")\n",
    "print(\"*\"*20) \n",
    "for tok in doc:\n",
    "    print((tok.text, tok.pos_))\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"The extracted noun phrases is: \")\n",
    "print(\"*\"*20) \n",
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Practice Exercise (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on the task above, can you parse the following text and text the noun phrases from that? You can also choose other tools and text that you are interested in to do the exercise. \n",
    "\n",
    "    \"Information science is that discipline that investigates the properties and behavior of information, the forces governing the flow of information, and the means of processing information for optimum accessibility and usability.\"\n",
    "\n",
    "-Borko, H. (1968). Information science: What is it? American Documentation, 19, 3. Retrieved from ASIST, [What is information science](https://www.asist.org/about/what-is-information-science/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import spacy                    \n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "text_1 = \"\"\"Information science is the discipline that investigates the properties and behavior of information, \n",
    "            the forces governing the flow of information, and the means of processing information for \n",
    "            optimum accessibility and usability.\"\"\"\n",
    "\n",
    "# here is your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information science\n",
      "the discipline\n",
      "that\n",
      "the properties\n",
      "behavior\n",
      "information\n",
      "the flow\n",
      "information\n",
      "information\n",
      "optimum accessibility\n",
      "usability\n"
     ]
    }
   ],
   "source": [
    "import spacy                    \n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "text_1 = \"\"\"Information science is the discipline that investigates the properties and behavior of information, \n",
    "            the forces governing the flow of information, and the means of processing information for \n",
    "            optimum accessibility and usability.\"\"\"\n",
    "\n",
    "# here is your code\n",
    "\n",
    "doc = nlp(text_1)\n",
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Name Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T17:52:01.108463Z",
     "start_time": "2020-05-29T17:52:01.104473Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"705\" height=\"537\" src=\"https://www.youtube.com/embed/d7kFYmvyZiQ?list=PL6IN6GlGifEytPcv5HR_iaNBekwXYZIpR\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"705\" height=\"537\" src=\"https://www.youtube.com/embed/d7kFYmvyZiQ?list=PL6IN6GlGifEytPcv5HR_iaNBekwXYZIpR\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Task 2: Extract Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this section, we will use spaCy to extract **Organization**, **Geopolitical entity**, **CARDINAL**, **Money** entities from the text. \n",
    "For Named entity uses OntoNotes 5 corpus to train its entity recognition model, spaCy supporting the detection of a wider variety of entities than NLTK. This corpus includes diverse data sources, e.g., telephone conversations, newswire, newsgroups, broadcast news, broadcast conversation, weblogs. More detail can be found [here](https://catalog.ldc.upenn.edu/LDC2013T19).   \n",
    "\n",
    "* *The NIH was founded in 1887 and is now part of the United States Department of Health and Human Services.* \n",
    "* *The NIH is located in Maryland, U.S. and has nearly 1,000 scientists and support staff.*\n",
    "* *The NIH obtained US$39 billion from Congress in 2019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### How to solve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Import spacy and english model\n",
    "* Using nlp() to obtain the attribute of each word in the text. nlp() helps you detect and extract the name entities. For more detail about what you can do with nlp(), you can find [here](https://spacy.io/usage/spacy-101)\n",
    "* You can either use doc.ents    \n",
    "```python\n",
    "doc = nlp(string_to_process)\n",
    "for ent in doc.ents:\n",
    "    print(ent.label)\n",
    "```\n",
    "    or get the words' attributes \"ent_type_\" to obtain the named entities.\n",
    "```python\n",
    "doc = nlp(string_to_process)\n",
    "for token in doc:\n",
    "    print(token.ent_type_)\n",
    "```\n",
    "\n",
    "* Visualize the entities within the sentence with displacy\n",
    "```python\n",
    "displacy.render(doc, style=\"ent\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Using doc.ent to directly get entities\n",
      "********************\n",
      "NIH: 5, 8, ORG\n",
      "April 1887: 24, 34, DATE\n",
      "the United States Department of Health and Human Services: 54, 111, ORG\n",
      "NIH: 117, 120, ORG\n",
      "Maryland: 135, 143, GPE\n",
      "U.S.: 145, 149, GPE\n",
      "1,000: 170, 175, CARDINAL\n",
      "NIH: 210, 213, ORG\n",
      "US$39 billion: 223, 236, MONEY\n",
      "Congress: 242, 250, ORG\n",
      "2019: 254, 258, DATE\n",
      "********************\n",
      "Using doc.token to directly get entities\n",
      "********************\n",
      "We are processing the text:  \n",
      "The NIH was founded in April 1887 and is now part of the United States Department of Health and Human Services.\n",
      "\n",
      "\n",
      ": \n",
      "The: \n",
      "NIH: ORG\n",
      "was: \n",
      "founded: \n",
      "in: \n",
      "April: DATE\n",
      "1887: DATE\n",
      "and: \n",
      "is: \n",
      "now: \n",
      "part: \n",
      "of: \n",
      "the: ORG\n",
      "United: ORG\n",
      "States: ORG\n",
      "Department: ORG\n",
      "of: ORG\n",
      "Health: ORG\n",
      "and: ORG\n",
      "Human: ORG\n",
      "Services: ORG\n",
      ".: \n",
      "\n",
      ": \n",
      "We are processing the text:  The NIH is located in Maryland, U.S. and contains nearly 1,000 scientists and support staff.\n",
      "\n",
      "The: \n",
      "NIH: ORG\n",
      "is: \n",
      "located: \n",
      "in: \n",
      "Maryland: GPE\n",
      ",: \n",
      "U.S.: GPE\n",
      "and: \n",
      "contains: \n",
      "nearly: \n",
      "1,000: CARDINAL\n",
      "scientists: \n",
      "and: \n",
      "support: \n",
      "staff: \n",
      ".: \n",
      "\n",
      ": \n",
      "We are processing the text:  The NIH obtained US$39 billion from Congress in 2019.\n",
      "\n",
      "The: \n",
      "NIH: ORG\n",
      "obtained: \n",
      "US$: MONEY\n",
      "39: MONEY\n",
      "billion: MONEY\n",
      "from: \n",
      "Congress: ORG\n",
      "in: \n",
      "2019: DATE\n",
      ".: \n",
      "\n",
      ": \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>The \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NIH\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " was founded in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    April 1887\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and is now part of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States Department of Health and Human Services\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</br>The \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NIH\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is located in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Maryland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and contains nearly \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " scientists and support staff.</br>The \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NIH\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " obtained \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US$39 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " from \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Congress\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy                    #import spacy module\n",
    "from spacy import displacy         # import NER visualizer\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "TEXT_SAMPLE = \"\"\"\n",
    "The NIH was founded in April 1887 and is now part of the United States Department of Health and Human Services.\n",
    "The NIH is located in Maryland, U.S. and contains nearly 1,000 scientists and support staff.\n",
    "The NIH obtained US$39 billion from Congress in 2019.\n",
    "\"\"\"\n",
    "\n",
    "# load English language model\n",
    "nlp = en_core_web_sm.load()\n",
    "# pass the text to nlp\n",
    "\n",
    "doc = nlp(TEXT_SAMPLE)\n",
    "\n",
    "# Extract the entities from such doc objects. We will get the following attributes of\n",
    "# the entity, i.e., original text, start position, end position, entity type\n",
    "print(\"*\"*20) \n",
    "print(\"Using doc.ent to directly get entities\")\n",
    "print(\"*\"*20) \n",
    "for ent in doc.ents:\n",
    "    print(\"{}: {}, {}, {}\".format(ent.text,      # original text\n",
    "                                ent.start_char,  # start position of each entity in that text\n",
    "                                ent.end_char,    # end position of each entity in that text\n",
    "                                ent.label_))         # entity type\n",
    "    \n",
    "# You can also access the attributes of each token directly. \n",
    "# Here we obtian the text, pos_tags, IOB entity label and named entity label.\n",
    "print(\"*\"*20) \n",
    "print(\"Using doc.token to directly get entities\")\n",
    "print(\"*\"*20) \n",
    "for sent in doc.sents:\n",
    "    print(\"We are processing the text: \", sent.text)      # print the sentence\n",
    "    for tok in sent:\n",
    "        print(\"{}: {}\".format(tok.text, tok.ent_type_))      # original text and entity type\n",
    "                                          \n",
    "# Visualize the entities displacy by specifying the visualization type as \"ent\"     \n",
    "displacy.render(doc, style=\"ent\")\n",
    "                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Practice Exercise (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on the task above, can you extract the PERSON, ORGANIZATION,  from the given text. You can also choose other tools and text that you are interested in to do the exercise. \n",
    "\n",
    "    \"Marc Lipsitch, a Harvard professor of epidemiology and the director of the Center for Communicable Disease Dynamics, created one of the first modeling tools used in the U.S. for the COVID-19 pandemic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import spacy                    #import spacy module\n",
    "from spacy import displacy         # import NER visualizer\n",
    "import en_core_web_sm\n",
    "\n",
    "text = \"\"\"Marc Lipsitch, a Harvard professor of epidemiology and the director of the Center for Communicable Disease Dynamics, \n",
    "            created one of the first modeling tools used in the U.S. for the COVID-19 pandemic\"\"\"\n",
    "# here is your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marc Lipsitch: 0, 13, PERSON\n",
      "Harvard: 17, 24, ORG\n",
      "the Center for Communicable Disease Dynamics: 71, 115, ORG\n",
      "COVID-19: 195, 203, ORG\n"
     ]
    }
   ],
   "source": [
    "import spacy                    #import spacy module\n",
    "from spacy import displacy         # import NER visualizer\n",
    "import en_core_web_sm\n",
    "\n",
    "text = \"\"\"Marc Lipsitch, a Harvard professor of epidemiology and the director of the Center for Communicable Disease Dynamics, \n",
    "            created one of the first modeling tools used in the U.S. for the COVID-19 pandemic\"\"\"\n",
    "# here is your code\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PERSON' or ent.label_ == 'ORG': # as we are outputing PERSON and ORGANIZATION only\n",
    "        print(\"{}: {}, {}, {}\".format(ent.text,      # original text\n",
    "                                    ent.start_char,  # start position of each entity in that text\n",
    "                                    ent.end_char,    # end position of each entity in that text\n",
    "                                    ent.label_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the previous sections, we are still analyzing text at a lexical level, i.e, the predefined label of words. In order to obtain more information from the text, syntactax structure analysis comes to play and provides us with the syntactic information in the text. The syntactax structure describes the arrangement of words and phrases to create well-formed sentences in a language. \n",
    "In this section, we will first look at the syntactic dependency structure, that is, how words group as a unit and how the units relate to each other. We will then introduce the universal dependency and end this section up with the extraction of subject-predicate-object relation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Syntactic Dependency Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T17:52:09.501036Z",
     "start_time": "2020-05-29T17:52:09.495055Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"705\" height=\"537\" src=\"https://www.youtube.com/embed/X3qgiSaDYzU?list=PL6IN6GlGifEytPcv5HR_iaNBekwXYZIpR\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"705\" height=\"537\" src=\"https://www.youtube.com/embed/X3qgiSaDYzU?list=PL6IN6GlGifEytPcv5HR_iaNBekwXYZIpR\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Additional Resources for the Dependency Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Universal dependency structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One thing we didn't mention in the video is the [Universal Dependency (UD) set](https://universaldependencies.org/). This set, provides an inventory of the dependency relations in human language. In this tutorial, we focus on English and will use this set for the dependency parsing and the relation extraction in the following section. See example: \n",
    "\n",
    "<img src = https://d3i71xaburhd42.cloudfront.net/273f54ea6f3631a78d9dd442609bb2033cfb1ffe/3-Figure14.2-1.png style=\"height:400px\"> Source: Jurafsky, D., & Martin, J.H. Speech and Language Processing. Dependency Parsing (p.275)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Task 3: Analyze Dependency Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this task we have three sentences with complex sturcture. We want to figure out the root of the entire sentence and the head of each words. Be sure to be familiar yourself with the Universal dependency tags. \n",
    "\n",
    "* *I remember that you have given Tom a gift* \n",
    "* *Bell makes and distributes computer products*\n",
    "* *The NIH is located in Maryland, U.S. and it contains nearly 1,000 scientists and support staff.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### How to solve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Get the dependency tags of each word and its head or dependents, if any, using spaCy. \n",
    "```python\n",
    "    # tok.dep_ gives the dependency function that the word plays, \n",
    "    # tok.head gives the head of the current word, notice that the head of the head verb in a sentence is itself\n",
    "    # tok.children gives all the dependents this word has. \n",
    "    # tok.rights, tok.lefts give you the dependents on its right and left\n",
    "    doc = nlp(text)\n",
    "    for tok in doc:\n",
    "        print(tok.dep_)\n",
    "        print(tok.head)\n",
    "        print(tok.children)\n",
    "        print(tok.rights)\n",
    "        print(tok.lefts)\n",
    "```\n",
    "* Visualize the dependency structure, specify the visualization style you want to present, which here is dependency \"dep\"\n",
    "```python\n",
    "    displacy.render(doc, style=\"dep\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"db615a7294584266b38b8ffd66262a77-0\" class=\"displacy\" width=\"950\" height=\"337.0\" direction=\"ltr\" style=\"max-width: none; height: 337.0px; color: black; background: #ffffff; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">remember</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">have</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">give</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Tom</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">gift</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-db615a7294584266b38b8ffd66262a77-0-0\" stroke-width=\"2px\" d=\"M62,202.0 62,185.33333333333334 141.0,185.33333333333334 141.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-db615a7294584266b38b8ffd66262a77-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,204.0 L58,196.0 66,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-db615a7294584266b38b8ffd66262a77-0-1\" stroke-width=\"2px\" d=\"M262,202.0 262,152.0 547.0,152.0 547.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-db615a7294584266b38b8ffd66262a77-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M262,204.0 L258,196.0 266,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-db615a7294584266b38b8ffd66262a77-0-2\" stroke-width=\"2px\" d=\"M362,202.0 362,168.66666666666666 544.0,168.66666666666666 544.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-db615a7294584266b38b8ffd66262a77-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,204.0 L358,196.0 366,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-db615a7294584266b38b8ffd66262a77-0-3\" stroke-width=\"2px\" d=\"M462,202.0 462,185.33333333333334 541.0,185.33333333333334 541.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-db615a7294584266b38b8ffd66262a77-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M462,204.0 L458,196.0 466,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-db615a7294584266b38b8ffd66262a77-0-4\" stroke-width=\"2px\" d=\"M162,202.0 162,135.33333333333331 550.0,135.33333333333331 550.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-db615a7294584266b38b8ffd66262a77-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550.0,204.0 L554.0,196.0 546.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-db615a7294584266b38b8ffd66262a77-0-5\" stroke-width=\"2px\" d=\"M562,202.0 562,185.33333333333334 641.0,185.33333333333334 641.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-db615a7294584266b38b8ffd66262a77-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M641.0,204.0 L645.0,196.0 637.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-db615a7294584266b38b8ffd66262a77-0-6\" stroke-width=\"2px\" d=\"M762,202.0 762,185.33333333333334 841.0,185.33333333333334 841.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-db615a7294584266b38b8ffd66262a77-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M762,204.0 L758,196.0 766,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-db615a7294584266b38b8ffd66262a77-0-7\" stroke-width=\"2px\" d=\"M562,202.0 562,168.66666666666666 844.0,168.66666666666666 844.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-db615a7294584266b38b8ffd66262a77-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M844.0,204.0 L848.0,196.0 840.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Dependent tag</th>\n",
       "      <th>Head</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Left dependents</th>\n",
       "      <th>Right dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>remember</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>remember</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>remember</td>\n",
       "      <td>[I, give]</td>\n",
       "      <td>[give]</td>\n",
       "      <td>[I]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that</td>\n",
       "      <td>mark</td>\n",
       "      <td>give</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>give</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>aux</td>\n",
       "      <td>give</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>give</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>remember</td>\n",
       "      <td>[that, you, have, Tom, gift]</td>\n",
       "      <td>[Tom, gift]</td>\n",
       "      <td>[that, you, have]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom</td>\n",
       "      <td>dative</td>\n",
       "      <td>give</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>det</td>\n",
       "      <td>gift</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gift</td>\n",
       "      <td>dobj</td>\n",
       "      <td>give</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[a]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Dependent tag      Head                    Dependents  \\\n",
       "0         I         nsubj  remember                            []   \n",
       "0  remember          ROOT  remember                     [I, give]   \n",
       "0      that          mark      give                            []   \n",
       "0       you         nsubj      give                            []   \n",
       "0      have           aux      give                            []   \n",
       "0      give         ccomp  remember  [that, you, have, Tom, gift]   \n",
       "0       Tom        dative      give                            []   \n",
       "0         a           det      gift                            []   \n",
       "0      gift          dobj      give                           [a]   \n",
       "\n",
       "  Left dependents   Right dependents  \n",
       "0              []                 []  \n",
       "0          [give]                [I]  \n",
       "0              []                 []  \n",
       "0              []                 []  \n",
       "0              []                 []  \n",
       "0     [Tom, gift]  [that, you, have]  \n",
       "0              []                 []  \n",
       "0              []                 []  \n",
       "0              []                [a]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"27729d2d55404c61836036d1f867abe9-0\" class=\"displacy\" width=\"650\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: black; background: #ffffff; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Bell</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">makes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">distributes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">computer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">products</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-27729d2d55404c61836036d1f867abe9-0-0\" stroke-width=\"2px\" d=\"M62,102.0 62,85.33333333333333 147.0,85.33333333333333 147.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-27729d2d55404c61836036d1f867abe9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,104.0 L58,96.0 66,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-27729d2d55404c61836036d1f867abe9-0-1\" stroke-width=\"2px\" d=\"M162,102.0 162,85.33333333333333 247.0,85.33333333333333 247.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-27729d2d55404c61836036d1f867abe9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M247.0,104.0 L251.0,96.0 243.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-27729d2d55404c61836036d1f867abe9-0-2\" stroke-width=\"2px\" d=\"M162,102.0 162,68.66666666666666 350.0,68.66666666666666 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-27729d2d55404c61836036d1f867abe9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M350.0,104.0 L354.0,96.0 346.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-27729d2d55404c61836036d1f867abe9-0-3\" stroke-width=\"2px\" d=\"M462,102.0 462,85.33333333333333 547.0,85.33333333333333 547.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-27729d2d55404c61836036d1f867abe9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M462,104.0 L458,96.0 466,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-27729d2d55404c61836036d1f867abe9-0-4\" stroke-width=\"2px\" d=\"M362,102.0 362,68.66666666666666 550.0,68.66666666666666 550.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-27729d2d55404c61836036d1f867abe9-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550.0,104.0 L554.0,96.0 546.0,96.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Dependent tag</th>\n",
       "      <th>Head</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Left dependents</th>\n",
       "      <th>Right dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bell</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>makes</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>makes</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>makes</td>\n",
       "      <td>[Bell, and, distributes]</td>\n",
       "      <td>[and, distributes]</td>\n",
       "      <td>[Bell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>makes</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distributes</td>\n",
       "      <td>conj</td>\n",
       "      <td>makes</td>\n",
       "      <td>[products]</td>\n",
       "      <td>[products]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer</td>\n",
       "      <td>compound</td>\n",
       "      <td>products</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>products</td>\n",
       "      <td>dobj</td>\n",
       "      <td>distributes</td>\n",
       "      <td>[computer]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[computer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word Dependent tag         Head                Dependents  \\\n",
       "0         Bell         nsubj        makes                        []   \n",
       "0        makes          ROOT        makes  [Bell, and, distributes]   \n",
       "0          and            cc        makes                        []   \n",
       "0  distributes          conj        makes                [products]   \n",
       "0     computer      compound     products                        []   \n",
       "0     products          dobj  distributes                [computer]   \n",
       "\n",
       "      Left dependents Right dependents  \n",
       "0                  []               []  \n",
       "0  [and, distributes]           [Bell]  \n",
       "0                  []               []  \n",
       "0          [products]               []  \n",
       "0                  []               []  \n",
       "0                  []       [computer]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d5db4af9df614a72bb321c9d20787d62-0\" class=\"displacy\" width=\"1650\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: black; background: #ffffff; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">NIH</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">located</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">Maryland,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">U.S.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">contains</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">nearly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">1,000</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">scientists</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1350\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1350\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">support</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">staff</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-0\" stroke-width=\"2px\" d=\"M62,152.0 62,135.33333333333334 144.0,135.33333333333334 144.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,154.0 L58,146.0 66,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-1\" stroke-width=\"2px\" d=\"M162,152.0 162,118.66666666666666 347.0,118.66666666666666 347.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M162,154.0 L158,146.0 166,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-2\" stroke-width=\"2px\" d=\"M262,152.0 262,135.33333333333334 344.0,135.33333333333334 344.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M262,154.0 L258,146.0 266,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-3\" stroke-width=\"2px\" d=\"M362,152.0 362,135.33333333333334 444.0,135.33333333333334 444.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M444.0,154.0 L448.0,146.0 440.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-4\" stroke-width=\"2px\" d=\"M462,152.0 462,135.33333333333334 544.0,135.33333333333334 544.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M544.0,154.0 L548.0,146.0 540.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-5\" stroke-width=\"2px\" d=\"M562,152.0 562,135.33333333333334 644.0,135.33333333333334 644.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M644.0,154.0 L648.0,146.0 640.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-6\" stroke-width=\"2px\" d=\"M362,152.0 362,118.66666666666666 747.0,118.66666666666666 747.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M747.0,154.0 L751.0,146.0 743.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-7\" stroke-width=\"2px\" d=\"M862,152.0 862,135.33333333333334 944.0,135.33333333333334 944.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M862,154.0 L858,146.0 866,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-8\" stroke-width=\"2px\" d=\"M362,152.0 362,102.0 950.0,102.0 950.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,154.0 L954.0,146.0 946.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-9\" stroke-width=\"2px\" d=\"M1062,152.0 1062,135.33333333333334 1144.0,135.33333333333334 1144.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1062,154.0 L1058,146.0 1066,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-10\" stroke-width=\"2px\" d=\"M1162,152.0 1162,135.33333333333334 1244.0,135.33333333333334 1244.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1162,154.0 L1158,146.0 1166,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-11\" stroke-width=\"2px\" d=\"M962,152.0 962,118.66666666666666 1247.0,118.66666666666666 1247.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1247.0,154.0 L1251.0,146.0 1243.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-12\" stroke-width=\"2px\" d=\"M1262,152.0 1262,135.33333333333334 1344.0,135.33333333333334 1344.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1344.0,154.0 L1348.0,146.0 1340.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-13\" stroke-width=\"2px\" d=\"M1462,152.0 1462,135.33333333333334 1544.0,135.33333333333334 1544.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1462,154.0 L1458,146.0 1466,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d5db4af9df614a72bb321c9d20787d62-0-14\" stroke-width=\"2px\" d=\"M1262,152.0 1262,118.66666666666666 1547.0,118.66666666666666 1547.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d5db4af9df614a72bb321c9d20787d62-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1547.0,154.0 L1551.0,146.0 1543.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Dependent tag</th>\n",
       "      <th>Head</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Left dependents</th>\n",
       "      <th>Right dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>det</td>\n",
       "      <td>NIH</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIH</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>located</td>\n",
       "      <td>[The]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[The]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "      <td>auxpass</td>\n",
       "      <td>located</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>located</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>located</td>\n",
       "      <td>[NIH, is, in, and, contains]</td>\n",
       "      <td>[in, and, contains]</td>\n",
       "      <td>[NIH, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>prep</td>\n",
       "      <td>located</td>\n",
       "      <td>[Maryland]</td>\n",
       "      <td>[Maryland]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "      <td>[,, U.S.]</td>\n",
       "      <td>[,, U.S.]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>appos</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>located</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>contains</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contains</td>\n",
       "      <td>conj</td>\n",
       "      <td>located</td>\n",
       "      <td>[it, scientists]</td>\n",
       "      <td>[scientists]</td>\n",
       "      <td>[it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nearly</td>\n",
       "      <td>advmod</td>\n",
       "      <td>1,000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,000</td>\n",
       "      <td>nummod</td>\n",
       "      <td>scientists</td>\n",
       "      <td>[nearly]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nearly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scientists</td>\n",
       "      <td>dobj</td>\n",
       "      <td>contains</td>\n",
       "      <td>[1,000, and, staff]</td>\n",
       "      <td>[and, staff]</td>\n",
       "      <td>[1,000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>scientists</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support</td>\n",
       "      <td>compound</td>\n",
       "      <td>staff</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff</td>\n",
       "      <td>conj</td>\n",
       "      <td>scientists</td>\n",
       "      <td>[support]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[support]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word Dependent tag        Head                    Dependents  \\\n",
       "0         The           det         NIH                            []   \n",
       "0         NIH     nsubjpass     located                         [The]   \n",
       "0          is       auxpass     located                            []   \n",
       "0     located          ROOT     located  [NIH, is, in, and, contains]   \n",
       "0          in          prep     located                    [Maryland]   \n",
       "0    Maryland          pobj          in                     [,, U.S.]   \n",
       "0           ,         punct    Maryland                            []   \n",
       "0        U.S.         appos    Maryland                            []   \n",
       "0         and            cc     located                            []   \n",
       "0          it         nsubj    contains                            []   \n",
       "0    contains          conj     located              [it, scientists]   \n",
       "0      nearly        advmod       1,000                            []   \n",
       "0       1,000        nummod  scientists                      [nearly]   \n",
       "0  scientists          dobj    contains           [1,000, and, staff]   \n",
       "0         and            cc  scientists                            []   \n",
       "0     support      compound       staff                            []   \n",
       "0       staff          conj  scientists                     [support]   \n",
       "\n",
       "       Left dependents Right dependents  \n",
       "0                   []               []  \n",
       "0                   []            [The]  \n",
       "0                   []               []  \n",
       "0  [in, and, contains]        [NIH, is]  \n",
       "0           [Maryland]               []  \n",
       "0            [,, U.S.]               []  \n",
       "0                   []               []  \n",
       "0                   []               []  \n",
       "0                   []               []  \n",
       "0                   []               []  \n",
       "0         [scientists]             [it]  \n",
       "0                   []               []  \n",
       "0                   []         [nearly]  \n",
       "0         [and, staff]          [1,000]  \n",
       "0                   []               []  \n",
       "0                   []               []  \n",
       "0                   []        [support]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "# !pip install benepar   # you may need to install the package if you don't have that\n",
    "import en_core_web_sm\n",
    "from spacy import displacy # import visualization tool\n",
    "from IPython.display import display\n",
    "\n",
    "# load English language model\n",
    "nlp = en_core_web_sm.load()\n",
    "# Set up the visualization options\n",
    "options = {\"compact\": True, \"bg\": \"#ffffff\",\n",
    "           \"color\": \"black\", \"font\": \"Source Sans Pro\", \"distance\": 100}\n",
    "\n",
    "TEXT_SAMPLE = [\"I remember that you have give Tom a gift\",\n",
    "               \"Bell makes and distributes computer products\",\n",
    "               \"The NIH is located in Maryland, U.S. and it contains nearly 1,000 scientists and support staff\"] \n",
    "\n",
    "for text in TEXT_SAMPLE:\n",
    "    \n",
    "    # Create a dataframe for an easy-to-see output\n",
    "    df = pd.DataFrame()\n",
    "    # Import the text and get nlp object\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Here parse the examples  using displacy.render method\n",
    "    displacy.render(doc, style=\"dep\", options=options)\n",
    "    \n",
    "    # Obtain the head and dependents of each word\n",
    "    for tok in doc:\n",
    "        df = df._append([{\n",
    "            \"Word\":tok.text,\n",
    "            \"Dependent tag\": tok.dep_,\n",
    "            \"Head\":tok.head,\n",
    "            \"Dependents\":list(tok.children),\n",
    "            \"Left dependents\":list(tok.rights),\n",
    "            \"Right dependents\":list(tok.lefts)\n",
    "        }])\n",
    "    \n",
    "    # Show table in a readable format\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Practice Exercise (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on the task above, can you parse and visualize the dependency structure of the following sentence. You can also choose other tools and text that you are interested in to do the exercise. \n",
    "\n",
    "    \"Marry was looking for her bag but nothing was founded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"Marry was looking for her bag but nothing was founded\"\n",
    "\n",
    "# here is your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e565af016f6f4ebb8c16c5f625dc3825-0\" class=\"displacy\" width=\"1050\" height=\"337.0\" direction=\"ltr\" style=\"max-width: none; height: 337.0px; color: black; background: #ffffff; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Marry</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">her</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">bag</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">but</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">nothing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">founded</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-0\" stroke-width=\"2px\" d=\"M62,202.0 62,168.66666666666666 244.0,168.66666666666666 244.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,204.0 L58,196.0 66,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-1\" stroke-width=\"2px\" d=\"M162,202.0 162,185.33333333333334 241.0,185.33333333333334 241.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M162,204.0 L158,196.0 166,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-2\" stroke-width=\"2px\" d=\"M262,202.0 262,185.33333333333334 341.0,185.33333333333334 341.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M341.0,204.0 L345.0,196.0 337.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-3\" stroke-width=\"2px\" d=\"M462,202.0 462,185.33333333333334 541.0,185.33333333333334 541.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M462,204.0 L458,196.0 466,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-4\" stroke-width=\"2px\" d=\"M362,202.0 362,168.66666666666666 544.0,168.66666666666666 544.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M544.0,204.0 L548.0,196.0 540.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-5\" stroke-width=\"2px\" d=\"M262,202.0 262,152.0 647.0,152.0 647.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M647.0,204.0 L651.0,196.0 643.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-6\" stroke-width=\"2px\" d=\"M762,202.0 762,168.66666666666666 944.0,168.66666666666666 944.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M762,204.0 L758,196.0 766,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-7\" stroke-width=\"2px\" d=\"M862,202.0 862,185.33333333333334 941.0,185.33333333333334 941.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M862,204.0 L858,196.0 866,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e565af016f6f4ebb8c16c5f625dc3825-0-8\" stroke-width=\"2px\" d=\"M262,202.0 262,135.33333333333331 950.0,135.33333333333331 950.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e565af016f6f4ebb8c16c5f625dc3825-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,204.0 L954.0,196.0 946.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Dependent tag</th>\n",
       "      <th>Head</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Left dependents</th>\n",
       "      <th>Right dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marry</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>looking</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>aux</td>\n",
       "      <td>looking</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>looking</td>\n",
       "      <td>[Marry, was, for, but, founded]</td>\n",
       "      <td>[for, but, founded]</td>\n",
       "      <td>[Marry, was]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for</td>\n",
       "      <td>prep</td>\n",
       "      <td>looking</td>\n",
       "      <td>[bag]</td>\n",
       "      <td>[bag]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her</td>\n",
       "      <td>poss</td>\n",
       "      <td>bag</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bag</td>\n",
       "      <td>pobj</td>\n",
       "      <td>for</td>\n",
       "      <td>[her]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[her]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>but</td>\n",
       "      <td>cc</td>\n",
       "      <td>looking</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nothing</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>founded</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>auxpass</td>\n",
       "      <td>founded</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>founded</td>\n",
       "      <td>conj</td>\n",
       "      <td>looking</td>\n",
       "      <td>[nothing, was]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nothing, was]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word Dependent tag     Head                       Dependents  \\\n",
       "0    Marry         nsubj  looking                               []   \n",
       "0      was           aux  looking                               []   \n",
       "0  looking          ROOT  looking  [Marry, was, for, but, founded]   \n",
       "0      for          prep  looking                            [bag]   \n",
       "0      her          poss      bag                               []   \n",
       "0      bag          pobj      for                            [her]   \n",
       "0      but            cc  looking                               []   \n",
       "0  nothing     nsubjpass  founded                               []   \n",
       "0      was       auxpass  founded                               []   \n",
       "0  founded          conj  looking                   [nothing, was]   \n",
       "\n",
       "       Left dependents Right dependents  \n",
       "0                   []               []  \n",
       "0                   []               []  \n",
       "0  [for, but, founded]     [Marry, was]  \n",
       "0                [bag]               []  \n",
       "0                   []               []  \n",
       "0                   []            [her]  \n",
       "0                   []               []  \n",
       "0                   []               []  \n",
       "0                   []               []  \n",
       "0                   []   [nothing, was]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy import displacy # import visualization tool\n",
    "from IPython.display import display\n",
    "\n",
    "text = \"Marry was looking for her bag but nothing was founded\"\n",
    "\n",
    "# here is your code\n",
    "\n",
    "# load English language model\n",
    "nlp = en_core_web_sm.load()\n",
    "# Set up the visualization options\n",
    "options = {\"compact\": True, \"bg\": \"#ffffff\",\n",
    "           \"color\": \"black\", \"font\": \"Source Sans Pro\", \"distance\": 100}\n",
    "    \n",
    "# Create a dataframe for an easy-to-see output\n",
    "df = pd.DataFrame()\n",
    "# Import the text and get nlp object\n",
    "doc = nlp(text)\n",
    "\n",
    "# Here parse the examples  using displacy.render method\n",
    "displacy.render(doc, style=\"dep\", options=options)\n",
    "\n",
    "# Obtain the head and dependents of each word\n",
    "for tok in doc:\n",
    "    df = df._append([{\n",
    "        \"Word\":tok.text,\n",
    "        \"Dependent tag\": tok.dep_,\n",
    "        \"Head\":tok.head,\n",
    "        \"Dependents\":list(tok.children),\n",
    "        \"Left dependents\":list(tok.rights),\n",
    "        \"Right dependents\":list(tok.lefts)\n",
    "    }])\n",
    "\n",
    "# Show table in a readable format\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the above section we discussed the dependency structure. It seems that we can use the syntactic dependency to extract the predicate-argument relation by traversing the dependency structure. In this part we will be discussing how we can leverage such dependency structure to figure out the **predicates and arguments** relation. \n",
    "This *Triple* relation consists of the entity pairs and their semantic relations, i.e., (Subject, Predicate, Object). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T17:52:13.587434Z",
     "start_time": "2020-05-29T17:52:13.581483Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"705\" height=\"537\" src=\"https://www.youtube.com/embed/ODph0mGwMEg?list=PL6IN6GlGifEytPcv5HR_iaNBekwXYZIpR\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"705\" height=\"537\" src=\"https://www.youtube.com/embed/ODph0mGwMEg?list=PL6IN6GlGifEytPcv5HR_iaNBekwXYZIpR\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Task 4: Extract Subject-Predicate-Object Relation (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the following, we will use spaCy to extract such relations. In the above example, \n",
    "\n",
    "* *I remember that you have give Tom a gift.*\n",
    "\n",
    "* *Bell makes and distributes computer products.* \n",
    "\n",
    "* *The NIH is located in Maryland, U.S. and it contains nearly 1,000 scientists and support staff*\n",
    "\n",
    "The expected outcome will be:\n",
    "\n",
    "```python\n",
    "([I], remember, [given])\n",
    "([you], given, [Tom, gift])\n",
    "([Bell], makes, [products])\n",
    "([Bell], distributes, [products])\n",
    "([], located, [NIH])\n",
    "([it], contains, [scientists, staff])\n",
    "```\n",
    "Before we dive into the code detail, feel free to play with the code by running **Code** cell and see what are the outcomes of the above tested codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### How to solve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Considering this implementation is a little bit complex, we will take one step at a time. \n",
    "\n",
    "* Import packages and initiate variables\n",
    "* Obtain all verbs of a sentence\n",
    "* Recognize subjects\n",
    "* Recognize objects\n",
    "* Recognize other subjects or objects conjunction dependents\n",
    "\n",
    "The basic coding logic is to create the function that take the input text and output the results, **getRelation(sent_string)**. Then we create three functions that play roles in the getRelation function, i.e.,  **getSubj(verb)**, **getObj(verb)** and **getConj(word)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### 1. Import packages and initiate variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will use these constant variables to select the word with targeted dependency labels. The variables includes typical dependency tags of subject and object. In addition to subject and object, we also need dependency tag of the conjunctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import spacy                             #import spacy module\n",
    "import en_core_web_sm                    #import language model\n",
    "\n",
    "from spacy.util import filter_spans      #import filter_spans to avoid duplicate matches\n",
    "from spacy.matcher import Matcher        #import Matcher object to perform regex matching\n",
    "nlp = en_core_web_sm.load()              #load English language model\n",
    "\n",
    "# All possible dependency tags of subject\n",
    "SUBJECTS_DEP = [\"nsubj\",  \"csubj\", \"expl\"]\n",
    "\n",
    "# Subjects with passive voice\n",
    "PASSIVE_SUBJ_DEP = [\"nsubjpass\", \"csubjpass\"]\n",
    "\n",
    "# All possible dependency tags of object\n",
    "OBJECTS_DEP = [\"dobj\", \"dative\", \"pobj\", \"oprd\", ]\n",
    "\n",
    "# Conjunction dependency tags\n",
    "CONJ_DEP = [\"cc\", \"conj\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### 2. Obtain all the verbs of a sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After we set up the initial settings. We want to constuct a function **getRelation(sent_string)** which will help us extract the relation. In this function, we will idenfify the verb, subject and object from the sentence. We obtain all the verbs of a sentence which is normally the root of a sentence and thus helps us find other sentence parts. We also want to exclude the auxiliary verbs and their passive forms, such as \"be\", \"do\", \"have\", \"can\". We will use the following code to extract the verbs. word.pos_ is the pos tag of each word, word.dep_ is the dependency tags of words. \n",
    "\n",
    "```python\n",
    "def getRelation(sent_string):\n",
    "    \n",
    "    doc = nlp(sent_string)\n",
    "    verb_rel_list = [word for word in doc \n",
    "                             if word.pos_ == 'VERB' and word.dep_ not in ['aux', 'auxpass']]\n",
    "```\n",
    "After this extraction, we take the verb as the argument of the function **getSubj(verb)** and **getObj(verb)** to get the subjects and objects.\n",
    "\n",
    "```python\n",
    "\n",
    "    # get the subjects and objects of this verb\n",
    "    tuple_list = []\n",
    "    # here get all verbs  \n",
    "    if verb_rel_list:\n",
    "        for verb in verb_rel_list:\n",
    "            subj = getSubj(verb)\n",
    "            obj = getObj(verb)\n",
    "            print(\"{}\".format((subj, verb, obj)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### 3. Recognize subjects: getSubj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* First add all words with the subject dependency labels.\n",
    "\n",
    "```python\n",
    "    subjs = []\n",
    "    subjs.extend([w for w in verb.lefts if w.dep_ in SUBJECTS_DEP and w.pos_ != \"DET\"])\n",
    "```\n",
    "\n",
    "* However, this cannot include all cases. There are some other situations to consider: \n",
    "    1. Passive voice, where the subject and object swap their position\n",
    "    2. Conjunction, where two verbs may share the same subject. This situation can be recursive, which means, multiple verbs can be possible --> *I create, implement, and revise the product*. In this case, the 'create' is the head of 'implement', and the 'implement' is the head of 'revise'. It thus would be better to use recursive function to iteratively find the head of the verb. \n",
    "    3. [clausal complement (ccomp, xcomp)](https://universaldependencies.org/u/dep/ccomp.html), such as 'I remembered to give...', 'She started to cry'. Both cases contain two verbs and the latter one (\"give\", \"cry\") is the dependent of the first one (\"remembered\", \"started\"). The former verb are the head (root) of the sentence.\n",
    "\n",
    "```python\n",
    "def getSubj(verb, limit_time = 3):\n",
    "    \n",
    "    subjs.extend(list(w.rights)[0] for w in verb.rights if w.dep_ == 'agent')\n",
    "    if len(subjs) == 0 and limit_time>0:\n",
    "        limit_time -= 1    \n",
    "        subjs.extend(getSubj(verb.head, limit_time))\n",
    "    else: \n",
    "        print(\"No subject identified: \", verb)\n",
    "```\n",
    "\n",
    "* In some cases a subject may include a conjunction part, such as apple and orange. This is also the subject. Therefore we construct another function getConj(word) which helps us find their subject \"friends\". For example, apple, orange and peach\n",
    "\n",
    "```python\n",
    "    subjs.extend([w for subj in subjs for w in getConj(subj)])\n",
    "    \n",
    "    return subjs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### 4. Recognize objects: getObj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* First add all words with object dependency labels\n",
    "```python\n",
    "    objs.extend([w for w in verb.rights if w.dep_ in OBJECTS_DEP])\n",
    "```\n",
    "* However, this cannot include all cases. There are several cases we need to consider:\n",
    "    1. Passive voice, where the subject and object swap their places\n",
    "    2. [clausal complement (ccomp, xcomp)](https://universaldependencies.org/u/dep/ccomp.html), such as 'He said that', 'I remember that'\n",
    "    3. Conjunction and prepostion phrase condition where the objects do not follow the verb directly. The 'relcl' is the conjunction condition where the current verb has a head which is actually the root of the sentence, e.g., create and implement. The 'implement' is the relcl of the 'create'. In prepostion phrase the object follows a preposition, rather than the verb, such as 'look for'. \n",
    "    \n",
    "```python\n",
    "\n",
    "    # Check if passive objects in left children if so the object will be the subject\n",
    "    objs.extend([w for w in verb.lefts if w.dep_ in PASSIVE_SUBJ_DEP])\n",
    "    \n",
    "    # Check complement clause, conjunction and prepostion condition\n",
    "    if len(objs) == 0:\n",
    "        # If the verb is relcl to the main verb, its head is its object, e.g., \"I saw the book you bought(relcl)\". Another example is \"the elements connected (acl) by a link\"  \n",
    "        \n",
    "        if verb.dep_ in [\"relcl\", \"acl\"] and verb.tag_ in [\"VBN\"]:\n",
    "            objs.append(verb.head)    \n",
    "        else:\n",
    "            for child in verb.rights:\n",
    "                \n",
    "                # Consider the clausal complement, get the action of the clause, which can be represented by the verb, \n",
    "                # such as I remember that she cried (remember, cry)\n",
    "                if child.dep_ in ['ccomp', 'xcomp']:\n",
    "                    objs.extend([child])\n",
    "                    break\n",
    "                \n",
    "                # Consider verb_prep condition where prep has the obj child, such as depends on\n",
    "                elif child.pos_ == 'ADP' and child.dep_ == 'prep':\n",
    "                    temp = [w_child for w_child in child.rights if w_child.dep_ in OBJECTS_DEP]\n",
    "                    if temp:\n",
    "                        objs.extend(temp)  \n",
    "                        break          \n",
    "                # Get the verb's child to check dependent verb\n",
    "                elif child.pos_ == 'VERB': \n",
    "                    temp = getObj(child)\n",
    "                    if temp:\n",
    "                        objs.extend(temp)\n",
    "                        break \n",
    "```\n",
    "* In some cases an object may include a conjunction part, such as apple, orange and peach. This is also the object. \n",
    "\n",
    "```python\n",
    "    objs.extend(w for obj in objs for w in getConj(obj))\n",
    "    \n",
    "    return objs\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### 5. Get the subject's or object's \"friends\": getConj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we construct the getConj function to capture the conjunction dependents. For example in \"apple, orange and peach\" the orange and peach are the depndents of apple.\n",
    "\n",
    "```python\n",
    "def getConj(word):\n",
    "    '''\n",
    "    Return the conjunction part of a token\n",
    "    '''\n",
    "    return [rchild for rchild in word.rights if rchild.dep_ == 'conj']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import spacy                             #import spacy module\n",
    "import en_core_web_sm                    #import language model\n",
    "\n",
    "from spacy.util import filter_spans      #import filter_spans to avoid duplicate matches\n",
    "from spacy.matcher import Matcher        #import Matcher object to perform regex matching\n",
    "nlp = en_core_web_sm.load()              #load English language model\n",
    "\n",
    "# All possible dependency tags of subject\n",
    "SUBJECTS_DEP = [\"nsubj\",  \"csubj\", \"expl\"]\n",
    "\n",
    "# Subjects with passive voice\n",
    "PASSIVE_SUBJ_DEP = [\"nsubjpass\", \"csubjpass\"]\n",
    "\n",
    "# All possible dependency tags of object\n",
    "OBJECTS_DEP = [\"dobj\", \"dative\", \"pobj\", \"oprd\", ]\n",
    "\n",
    "# Conjunction dependency tags\n",
    "CONJ_DEP = [\"cc\", \"conj\"]\n",
    "\n",
    "\n",
    "# Obtain subjects from the verb\n",
    "def getSubj(verb, limit_time = 3):\n",
    "    '''\n",
    "    Traverse the relation's dependency tree to collect subject\n",
    "    Arg: \n",
    "        verb: a verb of the sentence\n",
    "    Return: \n",
    "        A subject list           \n",
    "    '''\n",
    "    subjs = []\n",
    "    # check if conjunction (verb as conj to main sentence)\n",
    "    # check if verb's head is verb, if true, then call getSubj\n",
    "    \n",
    "    subjs.extend([w for w in verb.lefts if w.dep_ in SUBJECTS_DEP and w.pos_ != \"DET\"])\n",
    "    \n",
    "    # Check passive tone, if agent in the sentence, i.e., \"by\", collect agent's child as subject\n",
    "    subjs.extend(list(w.rights)[0] for w in verb.rights if w.dep_ == 'agent')\n",
    "\n",
    "    \n",
    "    if len(subjs) == 0 and verb.text != verb.head.text:\n",
    "            \n",
    "        #If verb has no subject, then trace back to its head verb use the subject in main sentence\n",
    "        limit_time -= 1    \n",
    "        \n",
    "        # recursively use this function to further find subject\n",
    "        subjs.extend(getSubj(verb.head, limit_time))\n",
    "        \n",
    "\n",
    "    # Get the shared dependency subject with the ones already identified in conjunction\n",
    "    # Obtain conjunct dependents of the leftmost conjunct, apple, orange and peach\n",
    "    subjs.extend([w for subj in subjs for w in getConj(subj)])\n",
    "    \n",
    "    return subjs\n",
    "\n",
    "def getObj(verb):\n",
    "    '''\n",
    "    Traverse the relation's dependency tree to collect objects\n",
    "    Arg: \n",
    "        verb: a verb of the sentence\n",
    "    Return: \n",
    "        A objects list    \n",
    "    '''\n",
    "    \n",
    "    # If there is only one verb in sentence\n",
    "    objs = []\n",
    "    \n",
    "    # Get the right children dependency of this verb\n",
    "    right_child = [w for w in verb.rights]\n",
    "    \n",
    "    # Collect objects\n",
    "    objs.extend([w for w in verb.rights if w.dep_ in OBJECTS_DEP])\n",
    "    \n",
    "    # here check agent \"by\" \n",
    "    # Check if passive objects in left children if so the object will be the subject\n",
    "    objs.extend([w for w in verb.lefts if w.dep_ in PASSIVE_SUBJ_DEP])\n",
    "                \n",
    "    # Check prepostion and conjunction condition\n",
    "    if len(objs) == 0:\n",
    "        # If the verb is relcl to the main verb, its head is its object, e.g., I saw the book you bought(relcl), or elements connected (acl) by a link    \n",
    "        if verb.dep_ in [\"relcl\", \"acl\"] and verb.tag_ in [\"VBN\"]:\n",
    "            objs.append(verb.head) \n",
    "            \n",
    "        else:\n",
    "            for child in verb.rights:\n",
    "                \n",
    "                # Consider the clausal complement, get the action of the clause, which can be represented by the verb, \n",
    "                # such as I remember that she cried (remember, cry)\n",
    "                if child.dep_ in ['ccomp', 'xcomp']:\n",
    "                    objs.extend([child])\n",
    "                    break\n",
    "                \n",
    "                # Consider verb_prep condition where prep has the obj child, such as depends on\n",
    "                elif child.pos_ == 'ADP' and child.dep_ == 'prep':\n",
    "                    temp = [w_child for w_child in child.rights if w_child.dep_ in OBJECTS_DEP]\n",
    "                    if temp:\n",
    "                        objs.extend(temp)  \n",
    "                        break         \n",
    "                \n",
    "                # Get the verb's child to check the dependent verb that share the same objects, e.g., make and develop software\n",
    "                elif child.pos_ == 'VERB': \n",
    "                    temp = getObj(child)\n",
    "                    if temp:\n",
    "                        objs.extend(temp)\n",
    "                        break              \n",
    "    \n",
    "    # Get the shared dependency subject with the ones already identified in conjunction\n",
    "    # Obtain conjunct dependents of the rightmost conjunct, apple, orange and peach\n",
    "    objs.extend(w for obj in objs for w in getConj(obj))   \n",
    "    \n",
    "    return objs\n",
    "\n",
    "def getConj(word):\n",
    "    '''\n",
    "    Return the conjunction part of a token\n",
    "    Arg: \n",
    "        word: a word with conjunction dependencies\n",
    "    Return: \n",
    "        A list of conjunction dependencies\n",
    "    '''\n",
    "    return [rchild for rchild in word.rights if rchild.dep_ == 'conj']\n",
    "\n",
    "\n",
    "def getRelation(sent_string):\n",
    "    \"\"\"\n",
    "    Obtain S-V-O tuple from the string\n",
    "    Arg: \n",
    "        sent string: A sentence string\n",
    "    Return: \n",
    "        A S-V-O tuple list, e.g., [(subject, relation, object), (subject, relation, object)]\n",
    "\n",
    "    \"\"\"\n",
    "    svo_tuple = []    # a list of tuple (subj, v, obj)\n",
    "    doc = nlp(sent_string)\n",
    "\n",
    "    # Use regex to collect the verb entity which represent relations, except the auxiliry part, am, is, are, can.     \n",
    "#     special_pattern = [{'DEP': \"auxpass\"}, \n",
    "#                        {'POS': \"VERB\"},\n",
    "#                        {'DEP': \"prep\", \"POS\": \"ADP\"}]\n",
    "\n",
    "    # Get the verb and conjunction word match\n",
    "\n",
    "    verb_rel_list = [word for word in doc \n",
    "                                     if word.pos_ == 'VERB' and word.dep_ not in ['aux', 'auxpass']]\n",
    "    \n",
    "    is_rel_list = [word for word in doc \n",
    "                                     if word.pos_ == 'VERB' and word.dep_ not in ['aux', 'auxpass']]\n",
    "\n",
    "    # get the subjects and objects of this verb\n",
    "    tuple_list = []\n",
    "    # here get all verbs  \n",
    "    if verb_rel_list:\n",
    "        for verb in verb_rel_list:\n",
    "            subj = getSubj(verb)\n",
    "            obj = getObj(verb)\n",
    "            print(\"{}\".format((subj, verb.lemma_, obj)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Play with the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can play with the code before you dive into the detail. Please run the **Code** section first and run the following cell. Replace the text in \n",
    "```python\n",
    "getRelation(text)\n",
    "```\n",
    "with the text you are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([I], 'remember', [given])\n",
      "([you], 'give', [Tom, gift])\n",
      "([Bell], 'make', [products])\n",
      "([Bell], 'distribute', [products])\n",
      "([], 'locate', [NIH])\n",
      "([it], 'contain', [scientists, staff])\n"
     ]
    }
   ],
   "source": [
    "TEXT_SAMPLE = \"\"\"\n",
    "I remember that you have given Tom a gift.\n",
    "Bell makes and distributes computer products.\n",
    "The NIH is located in Maryland, U.S. and it contains nearly 1,000 scientists and support staff.\n",
    "\"\"\"\n",
    "CHALLENGE_TEXT = \"\"\"\n",
    "Marry was looking for her bag but nothing was founded\n",
    "\"\"\"\n",
    "\n",
    "getRelation(TEXT_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Reference & Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Taylor A., Marcus M., Santorini B., The Penn Treebank: An Overview (2003), Text, Speech and Language Technology, vol 20 \n",
    "https://www.nltk.org/book/ch05.html   \n",
    "https://www.nltk.org/book/ch07.html   \n",
    "https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf    \n",
    "https://arxiv.org/ftp/arxiv/papers/1308/1308.0661.pdf   \n",
    "https://nlp.stanford.edu/software/dependencies_manual.pdf  \n",
    "https://universaldependencies.org/en/dep/xcomp.html  \n",
    "Wang, Y., Wang, L., Rastegar-Mojarad, M., Moon, S., Shen, F., Afzal, N., Liu, S., Zeng, Y., Mehrabi, S., Sohn, S., & Liu, H. (2018). [Clinical information extraction applications: A literature review. Journal of Biomedical Informatics](https://doi.org/10.1016/j.jbi.2017.11.011), 77, 34–49. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Available Clinical Text Mining Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we discussed in the video, there are many text mining tools you can use for clinical purposes. \n",
    "\n",
    "|     Name                                   |     Description                                                                                                                                                                                                           |     Website                                                                                                          |\n",
    "|--------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|\n",
    "|     cTAKES                                 |     Open-source NLP system based on UIMA   framework for extraction of information from electronic health records   unstructured clinical text                                                                            |     http://ctakes.apache.org/                                                                                        |\n",
    "|     MetaMap                                |     National Institutes of Health   (NIH)-developed NLP tool that maps biomedical text to UMLS concepts                                                                                                                   |     https://metamap.nlm.nih.gov/                                                                                     |\n",
    "|     MedLEE                                 |     NLP system that extracts, structures,   and encodes clinical information from narrative clinical notes                                                                                                                |     http://zellig.cpmc.columbia.edu/medlee/                                                                          |\n",
    "|     KnowledgeMap Concept Indexer (KMCI)    |     NLP system that identifies biomedical   concepts and maps them to UMLS concepts                                                                                                                                       |     https://medschool.vanderbilt.edu/cpm/center-precision-medicine-blog/kmci-knowledgemap-concept-indexer            |\n",
    "|     HITEx                                  |     Open-source NLP tool built on top of   the GATE framework for various tasks such as principal diagnoses extraction   and smoking status extraction                                                                    |     https://www.i2b2.org/software/projects/hitex/hitex_manual.html                                                   |\n",
    "|     MedEx                                  |     NLP tool used to recognize drug names,   dose, route, and frequency from free-text clinical records                                                                                                                   |     https://medschool.vanderbilt.edu/cpm/center-precision-medicine-blog/medex-tool-finding-medication-information    |\n",
    "|     MedTagger                              |     Open-source NLP pipeline based on UIMA   framework for indexing based on dictionaries, information extraction, and   machine learning–based named entity recognition from clinical text                               |     http://ohnlp.org/index.php/MedTagger                                                                             |\n",
    "|     ARC                                    |     Automated retrieval console (ARC) is an   open-source NLP pipeline that converts unstructured text to structured data   such as Systematized Nomenclature of Medicine – Clinical Terms (SNOMED CT) or   UMLS codes    |     http://blulab.chpc.utah.edu/content/arc-automated-retrieval-console                                              |\n",
    "|     Medtex                                 |     Clinical NLP software that extracts   meaningful information from narrative text to facilitate clinical staff in   decision-making process                                                                            |     https://aehrc.com/research/projects/medical-free-text-retrieval-and-analytics/#medtex                            |\n",
    "|     CLAMP                                  |     NLP software system based on UIMA   framework for clinical language annotation, modeling, processing and machine   learning                                                                                           |     https://sbmi.uth.edu/ccb/resources/clamp.htm                                                                     |\n",
    "|     MedXN                                  |     A tool to extract comprehensive   medication information from clinical narratives and normalize it to RxNorm                                                                                                          |     http://ohnlp.org/index.php/MedXN                                                                                 |\n",
    "|     MedTime                                |     A tool to extract temporal information   from clinical narratives and normalize it to the TIMEX3 standard                                                                                                             |     http://ohnlp.org/index.php/MedTime                                                                               |\n",
    "\n",
    "(Wang et al., 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
